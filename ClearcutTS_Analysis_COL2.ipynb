{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c134e9cd",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center>Trends In Forest Recovery After Stand Replacing Disturbance: A Spectrotemporal Evaluation Of Productivity In Southeastern Pine Forests</center></h1>\n",
    "\n",
    "<h4><center> Daniel J. Putnam </center></h4>\n",
    "\n",
    "<center> For partial fulfillment of the reqiurements for the Master of Science degree </center>\n",
    "<center> College of Natural Resources and Environment </center>\n",
    "<center> Virginia Polytechnic Institute and State University </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fb06f",
   "metadata": {},
   "source": [
    "## ------------------------------------COLLECTION 2 INVESTIGATION-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73021364",
   "metadata": {},
   "source": [
    "## Analysis Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87dce3",
   "metadata": {},
   "source": [
    "### _Libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a09c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from datetime import datetime\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ee.Authenticate(auth_mode='paste')\n",
    "#ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1cdbf3",
   "metadata": {},
   "source": [
    "### _Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25606093",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS5 = ee.ImageCollection(\"LANDSAT/LT05/C01/T1_SR\") # landsat 5\n",
    "LS7 = ee.ImageCollection(\"LANDSAT/LE07/C01/T1_SR\") # landsat 7\n",
    "LS8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\") # landsat 8\n",
    "LCMS = ee.ImageCollection(\"USFS/GTAC/LCMS/v2021-7\") # landscape Change Monitoring System\n",
    "NLCD_col = ee.ImageCollection(\"USGS/NLCD_RELEASES/2019_REL/NLCD\") # national landcover Database\n",
    "loblolly = ee.FeatureCollection(\"users/dputnam21/us_eco_l3_NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e295bb3",
   "metadata": {},
   "source": [
    "### _Priliminary set-up_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc39449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sample date range for disturbances\n",
    "startingD = ee.Date.fromYMD(1989,1,1)\n",
    "endingD = ee.Date.fromYMD(2011,12,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed0f26",
   "metadata": {},
   "source": [
    "### _Landsat Preprocessing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6658501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud masking based on the QA band : code taken from landsat example in data catalog in EE\n",
    "def LScloudMask(image):\n",
    "  qa = image.select('pixel_qa')\n",
    "    # removing cloud pixels if confiance is high, cloud shadow, snow\n",
    "  cloud = qa.bitwiseAnd(1 << 5).And(qa.bitwiseAnd(1 << 7)) \\\n",
    "            .Or(qa.bitwiseAnd(1 << 3)) \\\n",
    "            .Or(qa.bitwiseAnd(1 << 4))\n",
    "  return image.updateMask(cloud.Not())\n",
    "\n",
    "# Going to try removing the coverage overlap between LS5 and LS8 to try and fix some issues\n",
    "#LS5 = LS5.filterDate(start = '1984-01-01',opt_end = ee.Date('2013-04-11'))\n",
    "#LS8 = LS8.filterDate(start = ee.Date('2013-04-11'))\n",
    "\n",
    "# Lansat 5/7 & 8 differ in their band labeling, need to select the bands I'm going to use and rename them to\n",
    "# match each other before merging collections : bands I need [red,green,NIR,SWIR1,SWIR2]    \n",
    "LS8BandNames = ee.List(['B4','B3','B5','B6','B7','pixel_qa'])\n",
    "NewBandNames = ee.List(['B3','B2','B4','B5','B7','pixel_qa'])\n",
    "LS8 = LS8.select(LS8BandNames,NewBandNames)\n",
    "\n",
    "# adding the cloud mask per generation\n",
    "LS5 = LS5.map(LScloudMask)\n",
    "LS7 = LS7.map(LScloudMask)\n",
    "LS8 = LS8.map(LScloudMask)\n",
    "\n",
    "# merging the landsat 5 and 7 collections\n",
    "LS_stack = LS5.merge(LS8)\n",
    "LS_stack = LS_stack.merge(LS7)\n",
    "\n",
    "# data reduction on the image stack\n",
    "LS_stack = LS_stack.filterBounds(loblolly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5479171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining and adding vegetation indicies to landsat collection\n",
    "\n",
    "# Adding a function to calculate and add an NDVI band for a single image\n",
    "def addNDVI(image):\n",
    "  ndvi = image.normalizedDifference(['B4', 'B3']).rename('NDVI')\n",
    "  return image.addBands(ndvi)\n",
    "\n",
    "# Adding a function to calculate and add an NBR band for a single image.\n",
    "def addNBR(image):\n",
    "  nbr = image.normalizedDifference(['B4', 'B7']).rename('NBR')\n",
    "  return image.addBands(nbr)\n",
    "\n",
    "# Adding a function to calculate and add an MBI band for a single image.\n",
    "def addMBI(image):\n",
    "  MBI = image.expression(\n",
    "  \"MBI = ((b('B5') - b('B7') - b('B4')) / (b('B5') + b('B7') + b('B4'))) + 0.5\")\n",
    "  return image.addBands(MBI)\n",
    "\n",
    "# Adding a function to calculate and add an EVI2 band for a single image.\n",
    "def addEVI2(image):\n",
    "  EVI2 = image.expression(\n",
    "  \"EVI2 = 2.5 * ( b('B4') - b('B3') ) / ( b('B4') + ( 2.4 * b('B3')) + 1)\")\n",
    "  return image.addBands(EVI2)\n",
    "\n",
    "# Adding the indices to the filtered combined Landsat collection\n",
    "LS_stack_wVI = LS_stack.map(addNDVI)\n",
    "LS_stack_wVI = LS_stack_wVI.map(addNBR)\n",
    "LS_stack_wVI = LS_stack_wVI.map(addMBI)\n",
    "LS_stack_wVI = LS_stack_wVI.map(addEVI2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554452be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf60c8",
   "metadata": {},
   "source": [
    "## Stand Identification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701417ad",
   "metadata": {},
   "source": [
    "### _Landcover/Landuse Mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New NLCD/LCMS method\n",
    "# retrieve NLCD for each year\n",
    "NLCD_2001 = NLCD_col.filter(ee.Filter.eq('system:index', '2001')).first().select(\"landcover\")\n",
    "NLCD_2004 = NLCD_col.filter(ee.Filter.eq('system:index', '2004')).first().select(\"landcover\")\n",
    "NLCD_2006 = NLCD_col.filter(ee.Filter.eq('system:index', '2006')).first().select(\"landcover\")\n",
    "NLCD_2008 = NLCD_col.filter(ee.Filter.eq('system:index', '2008')).first().select(\"landcover\")\n",
    "NLCD_2011 = NLCD_col.filter(ee.Filter.eq('system:index', '2011')).first().select(\"landcover\")\n",
    "NLCD_2013 = NLCD_col.filter(ee.Filter.eq('system:index', '2013')).first().select(\"landcover\")\n",
    "NLCD_2016 = NLCD_col.filter(ee.Filter.eq('system:index', '2016')).first().select(\"landcover\")\n",
    "NLCD_2019 = NLCD_col.filter(ee.Filter.eq('system:index', '2019')).first().select(\"landcover\")\n",
    "\n",
    "# combine NLCD to image collection\n",
    "NLCDlandcover_col = ee.ImageCollection(ee.List([NLCD_2001,NLCD_2004,NLCD_2006,NLCD_2008,NLCD_2011,NLCD_2013,NLCD_2016,NLCD_2019]))\n",
    "\n",
    "# Function to remap NLCD classes of interest for conditional layer\n",
    "def remapNLCD(image):\n",
    "    image = ee.Image(image)\n",
    "    image = image.updateMask(ee.Image.constant(42).Or(ee.Image.constant(52)))\n",
    "    image = image.remap(ee.List([42,52]),ee.List([10,1]),defaultValue = None)\n",
    "    return image\n",
    "\n",
    "# Layer containing the summed values of pixels across the collection after remapping\n",
    "NLCDclassSum = NLCDlandcover_col.map(remapNLCD).reduce(ee.Reducer.sum())\n",
    "NLCDMask = NLCDclassSum.remap(ee.List([62,71,80]),ee.List([1,1,1]), defaultValue = None)\n",
    "\n",
    "# retrieve LCMS landuse classification\n",
    "LCMSlanduseCol = LCMS.select(\"Land_Use\")\n",
    "\n",
    "# A function to select only forest landuse class\n",
    "def remapLCMS(image):\n",
    "    image = ee.Image(image)\n",
    "    onlyForest = image.remap([3],[1], defaultValue = None)\n",
    "    return onlyForest\n",
    "\n",
    "LCMSlanduseSum = LCMSlanduseCol.map(remapLCMS).reduce(ee.Reducer.sum())\n",
    "\n",
    "# # combining the two layers into a landuse / landcover mask\n",
    "lulcMask = NLCDMask.updateMask(LCMSlanduseSum.gte(36))\n",
    "lulcMask = lulcMask.clip(loblolly) # clip mask to study boundaries for better loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69036e32",
   "metadata": {},
   "source": [
    "### _LCMS Fast change method_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065ec27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the LCMS Change metric to identify harvest areas in contrast to the max VI method\n",
    "# Filtering LCMS for the region and timeframe\n",
    "LCMSchange = LCMS.select('Change_Raw_Probability_Fast_Loss')\n",
    "\n",
    "def LCMSchangeSelection(image):\n",
    "    image = ee.Image(image)\n",
    "    minConfidence = 70\n",
    "    gtePercent = image.gte(ee.Image.constant(minConfidence))\n",
    "    gtePercent = gtePercent.updateMask(gtePercent.eq(1))\n",
    "    gtePercent = gtePercent.set({'year':image.date().get('year')})\n",
    "    outImage = gtePercent.updateMask(lulcMask).rename('remapped')\n",
    "    return outImage\n",
    "\n",
    "# applying the function to the LCMS\n",
    "FC_stack = LCMSchange.map(LCMSchangeSelection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60b469",
   "metadata": {},
   "source": [
    "### _Connected Pixel (Min stand size) mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de135c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to apply a connected pixel mask to the input image\n",
    "def conectPixls(InImage,minArea,maxPixels):\n",
    "    pixelCount = InImage.connectedPixelCount(maxPixels,False)\n",
    "    minPixelCount = ee.Image(minArea).divide(ee.Image.pixelArea())\n",
    "    outImage = InImage.updateMask(pixelCount.gte(minPixelCount))\n",
    "    return outImage\n",
    "\n",
    "# a function to be mapped accross an image collection and annually apply the connected pixels mask, also creates an\n",
    "# additional band to store the year of disturbance for each pixel\n",
    "def annualConectPixls(image):\n",
    "    conectPixlsMasked = conectPixls(image,40000,1024) # minimum stand size of 4 ha (represented in m3), maximum of 92 ha (represented in pixel count) (tool limit)\n",
    "    imgYear = image.get('year')\n",
    "    imgYearBand = ee.Image.constant(imgYear).uint16().rename('ChangeY')\n",
    "    imgYearBand = imgYearBand.updateMask(conectPixlsMasked)\n",
    "    return conectPixlsMasked.addBands(imgYearBand)\n",
    "\n",
    "FC_final = FC_stack.map(annualConectPixls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the summary images\n",
    "FC_final_changeN = FC_final.select('remapped').reduce(ee.Reducer.sum())\n",
    "FC_final_firstYear = FC_final.select('ChangeY').reduce(ee.Reducer.min())\n",
    "FC_final_lastYear = FC_final.select('ChangeY').reduce(ee.Reducer.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649db560",
   "metadata": {},
   "source": [
    "### _Disturbance Year mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to help to keep detected disturbances within a given window of time\n",
    "# first detected disturbance\n",
    "FC_final_changeN = FC_final_changeN.updateMask(FC_final_firstYear.gte(startingD.get('year')) \\\n",
    "                                               .And(FC_final_firstYear.lte(endingD.get('year')))\n",
    "                                              )\n",
    "# last detected disturbance\n",
    "FC_final_changeN = FC_final_changeN.updateMask(FC_final_lastYear.gte(startingD.get('year')) \\\n",
    "                                               .And(FC_final_lastYear.lte(endingD.get('year')))\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb197f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final potential sample pixels\n",
    "# An image representing pixels that meet all selection criteria\n",
    "potentialSamples = ee.Image.toUint8(FC_final_changeN.updateMask(FC_final_changeN.eq(1))).rename('remapped_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a73efb",
   "metadata": {},
   "source": [
    "### _Filter Selection to Only Include Homogenous, Non-Edge Groups of Pixels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c74481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge avoidence\n",
    "PS_connectedPixelCount = potentialSamples.reduceNeighborhood(ee.Reducer.count(),\n",
    "                                                             ee.Kernel.circle(2, 'pixels', False, 1),\n",
    "                                                             'mask',\n",
    "                                                             True\n",
    "                                                            )\n",
    "potentialSamples2 = potentialSamples.updateMask(PS_connectedPixelCount.gte(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f4b76a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cfac5",
   "metadata": {},
   "source": [
    "## Automatic Stand Selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee631b",
   "metadata": {},
   "source": [
    "### _Creating Sampling Areas Using Ecoregions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cbc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to convert the ecoregion code to an integer value\n",
    "def convertPropertyToBand(feat):\n",
    "    feat = ee.Feature(feat)\n",
    "    prop = feat.get('US_L3CODE')\n",
    "    propInt = ee.Number.parse(prop).toInt()\n",
    "    feat = feat.set({'numericL3ecocode':propInt})\n",
    "    return feat\n",
    "loblolly = loblolly.map(convertPropertyToBand)\n",
    "\n",
    "# Need to convert ecoregion feature collection and the property to integer in order for it to be used \n",
    "#     as the 'classBand' in the stratifiedSample fucntion\n",
    "ecoregionImage = ee.Image(loblolly.reduceToImage(['numericL3ecocode'],ee.Reducer.first()))\n",
    "ecoregionImage = ecoregionImage.cast({'first':'uint8'})\n",
    "ecoregionImage = ecoregionImage.clipToCollection(loblolly)\n",
    "\n",
    "# (old method), want to just export a single band\n",
    "# Adding ecoregion code as band to potential sample pixels\n",
    "#potentialSamples2 = potentialSamples2.addBands(ecoregionImage.select('first').rename('numericL3ecocode'))\n",
    "\n",
    "potentialSamples2 = ecoregionImage.select('first').rename('numericL3ecocode').updateMask(potentialSamples2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627a60b",
   "metadata": {},
   "source": [
    "### _Imports/Exports of Created Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90809049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## today's date\n",
    "today = str(datetime.now()).split(\" \")[0]\n",
    "today = today.replace(\"-\",\"_\")\n",
    "today = \"_\"+today\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the points created in the above cell to google drive (only way they will finish processing)\n",
    "# The export process will take about 15 minutes to complete\n",
    "#geemap.ee_export_vector_to_drive(samplePoints, 'EE_SamplePoints'+today, 'EarthEngine_Exports', file_format='shp', selectors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the points created in the above cell\n",
    "# samplePoints = ee.FeatureCollection('users/dputnam21/stratifiedSamplePoints_03022022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9965f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing points created in arcpro\n",
    "samplePoints = ee.FeatureCollection('users/dputnam21/samplePoints_06282022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6dfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running a batch export process to export the final potential samples raster\n",
    "# exportTask = ee.batch.Export.image.toDrive(image = potentialSamples2, \n",
    "#                                            description = 'PotentialSamples'+today, \n",
    "#                                            folder = 'EarthEngine_Exports', \n",
    "#                                            region = loblolly.geometry(), \n",
    "#                                            scale = 30, \n",
    "#                                            skipEmptyTiles = True,\n",
    "#                                            maxPixels = 3000000000,\n",
    "#                                            fileFormat = 'GeoTIFF', \n",
    "#                                            )\n",
    "# exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aaa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing raster of potential samples batch exported in above cell\n",
    "# potentialSamples2 = ee.Image('users/dputnam21/PotentialSamples_2022_06_14')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b09d5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ba187",
   "metadata": {},
   "source": [
    "### _Creating Random Sample Points_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ee5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to try just using the export table function to drive\n",
    "# samplePoints = potentialSamples2.stratifiedSample(numPoints = 50,\n",
    "#                                                  classValues = [34,35,45,63,64,65,66,67,68,71,73,74,75],\n",
    "#                                                  classPoints = [2,404,391,148,1,799,5,40,36,4,1,61,114],\n",
    "#                                                  region = loblolly,\n",
    "#                                                  classBand = 'b1',\n",
    "#                                                  scale = 30,\n",
    "#                                                  seed = 5,\n",
    "#                                                  dropNulls = True,\n",
    "#                                                  geometries = True,\n",
    "#                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65253083",
   "metadata": {},
   "source": [
    "### _Creating Point Buffers for Sampling_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction in the number of samplepoints for methodology testing\n",
    "sampleLimit = samplePoints.size().getInfo() # can change this to a number for testing purposes\n",
    "samplePoints2 = samplePoints.limit(ee.Number(sampleLimit),\n",
    "                                   'UniqueID',\n",
    "                                   True\n",
    "                                  )\n",
    "numSamples = samplePoints2.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ccf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to be mapped over point feature collection to create buffers\n",
    "def makeBuffers(feat):\n",
    "    inFeat = ee.Feature(feat)\n",
    "    buff = inFeat.buffer(distance = 60) # 60 meter buffer = 2 pixel radius to align with circlular kernel mask\n",
    "    return buff\n",
    "\n",
    "sampleCircles = samplePoints2.map(makeBuffers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de9c96",
   "metadata": {},
   "source": [
    "### Displaying images on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fb17f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LCMS landcover palette\n",
    "LCMSlcPalette = ['efff6b','ff2ff8','1b9d0c','97ffff','a1a1a1','c2b34a','1B1716']\n",
    "\n",
    "Map = geemap.Map(basemap=\"SATELLITE\")\n",
    "#Map.centerObject(loblolly,7)\n",
    "Map.centerObject(ee.Feature(ee.Geometry.Point([-77.2013,36.8497, ])),13)\n",
    "\n",
    "# This is the bottom of the layer order\n",
    "\n",
    "Map.addLayer(ee.Image().paint(loblolly, color = 'black',width = 3), name = 'ecoRegion Outlines')\n",
    "Map.addLayer(ecoregionImage.select('first'), vis_params = {'palette': LCMSlcPalette, 'min': 45, 'max':75}, name = 'Ecoregion Code Image',shown = False)\n",
    "Map.addLayer(NLCDMask, vis_params = {'palette': ['3182BD'],'min':1,'max':1}, name = 'NLCD Mask', shown = False)\n",
    "Map.addLayer(lulcMask, vis_params = {'palette': ['3C4856'],'min':1,'max':1}, name = 'LCMS + NLCD landcover mask', shown = False)\n",
    "Map.addLayer(FC_stack, vis_params = {'palette': ['B56285'],'min':0,'max':1}, name = 'FC (>70%) raw', shown = False)\n",
    "Map.addLayer(FC_final.select('remapped'), vis_params = {'palette': ['9FACBD'],'min':0,'max':1}, name = 'FC (>70%) Min Area', shown = False)\n",
    "Map.addLayer(FC_final_changeN,{'palette':['fee0d2','fc9272','de2d26'],'min':1,'max':5},'LCMS Fast Change Count',True)\n",
    "Map.addLayer(FC_final_firstYear,{'palette':['edf8b1','7fcdbb','2c7fb8'],'min' : 1995, 'max' : 2010},'LCMS Fast Change Year',False)\n",
    "Map.addLayer(potentialSamples2.select('numericL3ecocode'),{'palette':['7E3054'],'min':0,'max':1}, name = 'Potential Samples 2', shown = True)\n",
    "Map.addLayer(samplePoints,{'color':'blue'}, name = 'Stratified Random Samples',shown = True)\n",
    "\n",
    "# This is the top of the layer order\n",
    "\n",
    "# Adding a legend for exporting images of layers\n",
    "legend_keys = ['Final Potential Sample Pixels', 'Edge Pixels Removed']\n",
    "# colorS can be defined using either hex code or RGB (0-255, 0-255, 0-255)\n",
    "legend_colors = ['de2d26','fee0d2']\n",
    "\n",
    "Map.add_legend(\n",
    "    legend_keys=legend_keys, legend_colors=legend_colors, position='bottomright'\n",
    ")\n",
    "\n",
    "Map.addLayerControl()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37454912",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664e8ed",
   "metadata": {},
   "source": [
    "## Automatic Stand Selection Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877e2f6",
   "metadata": {},
   "source": [
    "### _Export of stand attributes & Environmental Variables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of environmental data\n",
    "elevation_image = ee.Image(\"USGS/3DEP/10m\").select('elevation')\n",
    "soilTexture_image = ee.Image(\"OpenLandMap/SOL/SOL_TEXTURE-CLASS_USDA-TT_M/v02\")\n",
    "soilGG = ee.Image(\"OpenLandMap/SOL/SOL_GRTGROUP_USDA-SOILTAX_C/v01\")\n",
    "phenology_col = ee.ImageCollection(\"MODIS/006/MCD12Q2\")\n",
    "soilPh = ee.Image(\"OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02\")\n",
    "\n",
    "forestOwnership = ee.Image('users/dputnam21/Butler2017Ownership')\n",
    "forestOwnership = forestOwnership.rename(['ownership'])\n",
    "\n",
    "# Creating topography variables from the elevation layer\n",
    "topography = ee.Terrain.products(elevation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02501074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to bin aspect values into 8 classes for better processing\n",
    "# Remap values.\n",
    "aspect = topography.select('aspect')\n",
    "binnedAspect = ee.Image(1) \\\n",
    ".where(aspect.gt(337.5).And(aspect.lte(22.5)), 1) \\\n",
    ".where(aspect.gt(22.5).And(aspect.lte(67.5)), 2) \\\n",
    ".where(aspect.gt(67.5).And(aspect.lte(112.5)), 3) \\\n",
    ".where(aspect.gt(112.5).And(aspect.lte(157.5)), 4) \\\n",
    ".where(aspect.gt(157.5).And(aspect.lte(202.5)), 5) \\\n",
    ".where(aspect.gt(202.5).And(aspect.lte(247.5)), 6) \\\n",
    ".where(aspect.gt(247.5).And(aspect.lte(292.5)), 7) \\\n",
    ".where(aspect.gt(292.5).And(aspect.lte(337.5)), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ee.List.sequence(1984, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRIDMET Processing ###\n",
    "climate_col = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\")\n",
    "climate_col = climate_col.filter(ee.Filter.calendarRange(1984,2021,'year'))\n",
    "baseTemp = (5.5) # degrees celcius at which loblolly pine growth stops\n",
    "\n",
    "# Function to calculated GDD for each day\n",
    "def calcGDD(singleDayImage):\n",
    "    singleDayImage = ee.Image(singleDayImage) \n",
    "    maxTemp = singleDayImage.select('tmmx').subtract(273.15)\n",
    "    minTemp = singleDayImage.select('tmmn').subtract(273.15)\n",
    "    GDD1 = maxTemp.add(minTemp)\n",
    "    GDD2 = GDD1.divide(2)\n",
    "    GDD3 = GDD2.subtract(baseTemp)\n",
    "    GDD4 = GDD3.rename('GDD')\n",
    "    GDD5 = GDD4.set('system:time_start',maxTemp.get('system:time_start'))\n",
    "    return singleDayImage.addBands(GDD5)\n",
    "\n",
    "# Function to calculate cumulative growing degree days for each year\n",
    "def calcCumulativeGDD(year):\n",
    "    singleYear_col = climate_col.select('GDD').filter(ee.Filter.calendarRange(year, year, 'year'))\n",
    "    cumulativeGDD = singleYear_col.sum()\n",
    "    cumulativeGDD = cumulativeGDD.set('system:time_start', ee.Date.fromYMD(year,1, 1).millis())\n",
    "    return cumulativeGDD\n",
    "\n",
    "# Function to identify below freezing days\n",
    "def calcFreezeDays(singleDayImage):\n",
    "    singleDayImage = ee.Image(singleDayImage)\n",
    "    minTemp = singleDayImage.select('tmmn').subtract(273.15)\n",
    "    freeze = minTemp.updateMask(minTemp.lte(0))\n",
    "    return singleDayImage.addBands(freeze.rename('below_0'))\n",
    "\n",
    "# Calculate total number of below freezing days per year\n",
    "def annualFreezeDays(year):\n",
    "    singleYear_col = climate_col.select('below_0').filter(ee.Filter.calendarRange(year, year, 'year'))\n",
    "    below0_count = singleYear_col.reduce(ee.Reducer.count())\n",
    "    below0_count = below0_count.set('system:time_start', ee.Date.fromYMD(year,1, 1).millis())\n",
    "    return below0_count\n",
    "\n",
    "# Creating average temperature and vapor pressure deficit values for growing season months\n",
    "def calcGrowingSeasonVars(year):\n",
    "    singleYear_col = climate_col.filterDate(ee.Date.fromYMD(year,3,1),ee.Date.fromYMD(year,10,31))\n",
    "    maxTemp = singleYear_col.select('tmmx').mean().subtract(273.15)\n",
    "    minTemp = singleYear_col.select('tmmn').mean().subtract(273.15)\n",
    "    avgTemp1 = maxTemp.add(minTemp)\n",
    "    avgTemp2 = avgTemp1.divide(2)\n",
    "    avgTemp2 = avgTemp2.set('system:time_start', ee.Date.fromYMD(year,7, 1).millis())\n",
    "    avgTemp2 = avgTemp2.rename('AVGgrowSZNtemp')\n",
    "    avgVPD = singleYear_col.select('vpd').mean()\n",
    "    avgVPD = avgVPD.set('system:time_start', ee.Date.fromYMD(year,7, 1).millis())\n",
    "    avgVPD = avgVPD.rename('AVGgrowSZNvpd')\n",
    "    totalPrecip = singleYear_col.select('pr').sum()\n",
    "    totalPrecip = totalPrecip.set('system:time_start', ee.Date.fromYMD(year,7, 1).millis())\n",
    "    totalPrecip = totalPrecip.rename('TotalgrowSZNprecip')\n",
    "    avgVPD = avgVPD.addBands(totalPrecip)\n",
    "    return avgTemp2.addBands(avgVPD)\n",
    "\n",
    "climate_col = climate_col.map(calcGDD)\n",
    "climate_col = climate_col.map(calcFreezeDays)\n",
    "\n",
    "GDD_col = ee.ImageCollection(years.map(calcCumulativeGDD))\n",
    "freeze_col = ee.ImageCollection(years.map(annualFreezeDays))\n",
    "growSZN_col = ee.ImageCollection(years.map(calcGrowingSeasonVars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at potential changes over time\n",
    "GDD1984 = GDD_col.filter(ee.Filter.calendarRange(1984, 1989, 'year')).mean()\n",
    "GDD2021 = GDD_col.filter(ee.Filter.calendarRange(2016, 2021, 'year')).mean()\n",
    "GDDChange = ee.Image(GDD2021.subtract(GDD1984))\n",
    "\n",
    "freeze1984 = freeze_col.filter(ee.Filter.calendarRange(1984, 1989, 'year')).mean()\n",
    "freeze2021 = freeze_col.filter(ee.Filter.calendarRange(2016, 2021, 'year')).mean()\n",
    "freezeChange = ee.Image(freeze2021.subtract(freeze1984))\n",
    "\n",
    "growSZN1984 = growSZN_col.filter(ee.Filter.calendarRange(1984, 1989, 'year')).mean()\n",
    "growSZN2021 = growSZN_col.filter(ee.Filter.calendarRange(2016, 2021, 'year')).mean()\n",
    "growSZNChange = ee.Image(growSZN2021.subtract(growSZN1984))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffe44f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import geemap.colormaps as cm\n",
    "Map2 = geemap.Map(basemap=\"SATELLITE\")\n",
    "Map2.centerObject(loblolly,5)\n",
    "\n",
    "aspectPalette = ['#ffffcc','#ffeda0','#fed976','#feb24c','#fd8d3c','#fc4e2a','#e31a1c','#b10026']\n",
    "soilPalette = ['#d5c36b','#b96947','#9d3706','#ae868f','#f86714','#46d143','#368f20','#3e5a14','#ffd557','#fff72e','#ff5a9d','#ff005b']\n",
    "soilPhPalette = [\"FF0000\",\"FF1C00\",\"FF3900\",\"FF5500\",\"FF7100\",\"FF8E00\",\"FFAA00\",\"FFC600\",\"FFE200\",\"FFFF00\",\"E3FF00\",\"C7FF00\",\"AAFF00\",\"8EFF00\",\"72FF00\",\"55FF00\",\"39FF00\",\"1DFF00\",\"01FF00\",\"00FF1C\",\"00FF38\",\"00FF54\",\"00FF71\",\"00FF8D\",\"00FFA9\",\"00FFC6\",\"00FFE2\",\"00FFFE\",\"00E3FF\",\"00C7FF\",\"00ABFF\",\"008FFF\",\"0072FF\",\"0056FF\",\"003AFF\",\"001DFF\",\"0001FF\",\"1B00FF\",\"3800FF\",\"5400FF\"]\n",
    "Map2.addLayer(topography.select('elevation'), name = 'Elevation',vis_params = {'palette': ['black','white'],'min':0,'max':600},shown = False)\n",
    "Map2.addLayer(binnedAspect, name = 'Aspect',vis_params = {'palette': aspectPalette,'min':0,'max':8},shown = False)\n",
    "Map2.addLayer(topography.select('slope'), name = 'Topographical Slope',vis_params = {'palette': ['#253494','#41B6C4','#FFFFCC'],'min':0,'max':12},shown = False)\n",
    "Map2.addLayer(soilTexture_image.select('b0'), name = 'Soil Texture Class', vis_params = {'palette': soilPalette,'min':1,'max':12},shown = False)\n",
    "Map2.addLayer(soilPh.select('b30'), name = 'Soil Ph 30cm', vis_params = {'palette': soilPhPalette,'min':42,'max':110},shown = False)\n",
    "Map2.addLayer(GDD_col.first(), name = '1984 GDD', vis_params = {'palette': ['#f7fcb9','#addd8e','#31a354'],'min':3000,'max':6000},shown = False)\n",
    "Map2.addLayer(GDDChange, name = 'GDD 2021 - 1984', vis_params = {'palette': ['#f7fcb9','#addd8e','#31a354'],'min':100,'max':500},shown = False)\n",
    "Map2.addLayer(freeze_col.first(), name = '1984 Freeze days', vis_params = {'palette': ['#deebf7','#9ecae1','#3182bd'],'min':10,'max':170},shown = False)\n",
    "Map2.addLayer(freezeChange, name = 'Freeze days 2021 - 1984', vis_params = {'palette': ['#deebf7','#9ecae1','#3182bd'],'min':-20,'max':20},shown = False)\n",
    "Map2.addLayer(growSZN_col.select('AVGgrowSZNtemp').first(), name = '1984 Growing Season AVG temp', vis_params = {'palette': ['#ffeda0','#feb24c','#f03b20'],'min':15,'max':25},shown = False)\n",
    "Map2.addLayer(growSZN_col.select('AVGgrowSZNvpd').first(), name = '1984 Growing Season AVG vpd', vis_params = {'palette': ['#2c7fb8','#edf8b1','#f03b20'],'min':0,'max':3},shown = False)\n",
    "Map2.addLayer(growSZN_col.select('TotalgrowSZNprecip').first(), name = '1984 Growing Season Total Precip', vis_params = {'palette': ['#2c7fb8','#edf8b1','#f03b20'],'min':100,'max':700},shown = False)\n",
    "Map2.addLayer(growSZNChange.select('AVGgrowSZNtemp'), name = 'AVG growing season temp 2021 - 1984', vis_params = {'palette': ['#ffeda0','#feb24c','#f03b20'],'min':0,'max':3},shown = False)\n",
    "Map2.addLayer(growSZNChange.select('AVGgrowSZNvpd'), name = 'AVG growing season vpd 2021 - 1984', vis_params = {'palette': ['#2c7fb8','#edf8b1','#f03b20'],'min':-0.5,'max':0.5},shown = False)\n",
    "Map2.addLayer(growSZNChange.select('TotalgrowSZNprecip'), name = 'AVG total growing season precip 2021 - 1984', vis_params = {'palette': ['#2c7fb8','#edf8b1','#f03b20'],'min':0,'max':300},shown = False)\n",
    "Map2.addLayer(samplePoints2.draw(color = 'blue', pointRadius = 2, strokeWidth = 1), name = 'Samples',shown = False)\n",
    "Map2.addLayer(ee.Image().paint(loblolly, color = 'black',width = 3), name = 'ecoRegion Outlines')\n",
    "\n",
    "#Map2.add_colorbar_branca(colors = ['red','blue',], vmin=0, vmax=365, label=\"\")\n",
    "\n",
    "Map2.addLayerControl()\n",
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6d0f2",
   "metadata": {},
   "source": [
    "### _Ecoregion, Location, Topography, Soil Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting topography and soil texture variables ###\n",
    "\n",
    "# Mean elevation\n",
    "standAttributes_FC = topography.select('elevation').reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(),\n",
    "                                                               scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'elevation_mean': feat.get('mean')}))\n",
    "\n",
    "# Mean slope\n",
    "standAttributes_FC = topography.select('slope').reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mean(),\n",
    "                                                           scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'slope_mean': feat.get('mean')}))\n",
    "\n",
    "# Mode of binned Aspect\n",
    "standAttributes_FC = binnedAspect.reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(),\n",
    "                                                           scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'aspect_mode': feat.get('mode')}))\n",
    "\n",
    "# Mean Soil pH @ 30cm from Surface\n",
    "standAttributes_FC = soilPh.reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mean(),\n",
    "                                                           scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'pH30_mean': feat.get('mean')}))\n",
    "\n",
    "# Mode Soil Texture @ 0cm from surface\n",
    "standAttributes_FC = soilTexture_image.select('b0').reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(),\n",
    "                                                               scale = 250)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'soil0_mode': feat.get('mode')}))\n",
    "\n",
    "# Mode Soil Texture @ 30cm from surface\n",
    "standAttributes_FC = soilTexture_image.select('b30').reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(),\n",
    "                                                               scale = 250)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'soil30_mode': feat.get('mode')}))\n",
    "\n",
    "# Mode Soil Texture @ 100cm from surface\n",
    "standAttributes_FC = soilTexture_image.select('b100').reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(),\n",
    "                                                               scale = 250)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'soil100_mode': feat.get('mode')}))\n",
    "\n",
    "# Mode Soil Great Group taxonomy\n",
    "standAttributes_FC = soilGG.select('grtgroup').reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(),\n",
    "                                                               scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'soilGG_mode': feat.get('mode')}))\n",
    "\n",
    "# Butler 2017 Forest Ownership class\n",
    "standAttributes_FC = forestOwnership.reduceRegions(collection = standAttributes_FC,reducer = ee.Reducer.mode(), \n",
    "                                                              scale = 30)\n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set({'ownership_mode': feat.get('mode')}))\n",
    "\n",
    "# Adding a lat and long values \n",
    "standAttributes_FC = standAttributes_FC.map(lambda feat : feat.set(\n",
    "    {'lat': ee.Feature(feat.centroid()).geometry().coordinates().get(1),\n",
    "     'long': ee.Feature(feat.centroid()).geometry().coordinates().get(0)})\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a batch export process to execute the processes above\n",
    "\n",
    "exports = ['UniqueID','lat','long','Classified','aspect_mode','elevation_mean','slope_mean','soil0_mode','soil30_mode','soil100_mode','pH30_mean','soilGG_mode','ownership_mode']\n",
    "\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = standAttributes_FC,\n",
    "                                            description = (\"standAttribute_values\"+today),\n",
    "                                            folder = 'EarthEngine_Exports',\n",
    "                                            fileFormat = 'CSV',\n",
    "                                            selectors = exports\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0807c",
   "metadata": {},
   "source": [
    "### _Climate Data Extraction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "growSZNtemp_col = growSZN_col.select('AVGgrowSZNtemp')\n",
    "growSZNvpd_col = growSZN_col.select('AVGgrowSZNvpd')\n",
    "growSZNprecip_col = growSZN_col.select('TotalgrowSZNprecip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19249d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting GDD time series\n",
    "\n",
    "def createClimateTS(year):\n",
    "    singleY = GDD_col.filter(ee.Filter.calendarRange(year, year, 'year')).first()\n",
    "    export_FC = singleY.reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(), \n",
    "                                                          scale = 30)\n",
    "    export_FC = export_FC.map(lambda feat : feat.set({ee.String(ee.Number.toUint16(year).format()): feat.get('mean')}))\n",
    "    return export_FC\n",
    "\n",
    "exportCollection = ee.FeatureCollection(years.map(createClimateTS)).flatten()\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = exportCollection,\n",
    "                                           description = ('GDD_TS'+today),\n",
    "                                           folder = 'EarthEngine_Exports',\n",
    "                                           fileFormat = 'CSV'\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Freezing Days time series\n",
    "\n",
    "def createClimateTS(year):\n",
    "    singleY = freeze_col.filter(ee.Filter.calendarRange(year, year, 'year')).first()\n",
    "    export_FC = singleY.reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(), \n",
    "                                                          scale = 30)\n",
    "    export_FC = export_FC.map(lambda feat : feat.set({ee.String(ee.Number.toUint16(year).format()): feat.get('mean')}))\n",
    "    return export_FC\n",
    "\n",
    "exportCollection = ee.FeatureCollection(years.map(createClimateTS)).flatten()\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = exportCollection,\n",
    "                                           description = ('freeze_TS'+today),\n",
    "                                           folder = 'EarthEngine_Exports',\n",
    "                                           fileFormat = 'CSV'\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Growing season vpd time series\n",
    "\n",
    "def createClimateTS(year):\n",
    "    singleY = growSZNvpd_col.filter(ee.Filter.calendarRange(year, year, 'year')).first()\n",
    "    export_FC = singleY.reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(), \n",
    "                                                          scale = 30)\n",
    "    export_FC = export_FC.map(lambda feat : feat.set({ee.String(ee.Number.toUint16(year).format()): feat.get('mean')}))\n",
    "    return export_FC\n",
    "\n",
    "exportCollection = ee.FeatureCollection(years.map(createClimateTS)).flatten()\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = exportCollection,\n",
    "                                           description = ('meanVPD_TS'+today),\n",
    "                                           folder = 'EarthEngine_Exports',\n",
    "                                           fileFormat = 'CSV'\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Growing season temperature time series\n",
    "\n",
    "def createClimateTS(year):\n",
    "    singleY = growSZNtemp_col.filter(ee.Filter.calendarRange(year, year, 'year')).first()\n",
    "    export_FC = singleY.reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(), \n",
    "                                                          scale = 30)\n",
    "    #export_FC = export_FC.map(lambda feat : feat.set({ee.String(ee.Number.toUint16(year).format()): feat.get('mean')}))\n",
    "    return export_FC\n",
    "\n",
    "exportCollection = ee.FeatureCollection(years.map(createClimateTS)).flatten()\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = exportCollection,\n",
    "                                           description = ('meanTemp_TS'+today),\n",
    "                                           folder = 'EarthEngine_Exports',\n",
    "                                           fileFormat = 'CSV',\n",
    "                                           selectors = ['UniqueID','mean']\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Growing season precipitation time series\n",
    "\n",
    "def createClimateTS(year):\n",
    "    singleY = growSZNprecip_col.filter(ee.Filter.calendarRange(year, year, 'year')).first()\n",
    "    export_FC = singleY.reduceRegions(collection = sampleCircles,reducer = ee.Reducer.mean(), \n",
    "                                                          scale = 30)\n",
    "    export_FC = export_FC.map(lambda feat : feat.set({ee.String(ee.Number.toUint16(year).format()): feat.get('mean')}))\n",
    "    return export_FC\n",
    "\n",
    "exportCollection = ee.FeatureCollection(years.map(createClimateTS)).flatten()\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = exportCollection,\n",
    "                                           description = ('totalPrecip_TS'+today),\n",
    "                                           folder = 'EarthEngine_Exports',\n",
    "                                           fileFormat = 'CSV'\n",
    "                                          )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ee.List.sequence(1984, 2021)\n",
    "compositeMonthStart = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22378f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting time series for each climate scenario for each stand\n",
    "start = datetime.now() # figuring out how long this takes to run\n",
    "print(\"Extraction initiated :\",start)\n",
    "\n",
    "# # Extracting Climate data\n",
    "# test_col = sampleCircles.limit(ee.Number(20),\n",
    "#                               'UniqueID',\n",
    "#                               True\n",
    "#                                )\n",
    "\n",
    "singleYlists = []\n",
    "    \n",
    "for year in range(1984,2022): # 2022 not inclusive, collection 1 ends at end of 2021\n",
    "    print(year,end = '->-')\n",
    "    filteredColl = climate_col.filter(ee.Filter.calendarRange(year, year, 'year'))\n",
    "    threeBandImage = filteredColl.reduce(ee.Reducer.mean()) # mean annual value for each variable\n",
    "    proj = potentialSamples2.select('numericL3ecocode').projection()\n",
    "    if len(threeBandImage.bandNames().getInfo()) < 3 :\n",
    "        singleYlists.append([None]*len(stand_nums))\n",
    "    else :\n",
    "        # Extracting precipitation values\n",
    "        pointPrecipValCol = threeBandImage.select('ppt_sum').reduceRegions(collection = sampleCircles,\n",
    "                                                    reducer = ee.Reducer.first(), \n",
    "                                                    crs = proj,\n",
    "                                                    scale = 30 # Same scale as projection and landsat data\n",
    "                                                    )\n",
    "\n",
    "        pointPrecipValCol = pointPrecipValCol.set({'year':year})\n",
    "        pointPrecipValCol = pointPrecipValCol.map(fillNA) \n",
    "        PrecipVals = pointPrecipValCol.aggregate_array('first').getInfo()\n",
    "        \n",
    "        # Extracting mean temperature values\n",
    "        pointTempValCol = threeBandImage.select('tmean_mean').reduceRegions(collection = sampleCircles,\n",
    "                                                    reducer = ee.Reducer.first(), \n",
    "                                                    crs = proj,\n",
    "                                                    scale = 30 # Same scale as projection and landsat data\n",
    "                                                    )\n",
    "\n",
    "        pointTempValCol = pointTempValCol.set({'year':year})\n",
    "        pointTempValCol = pointTempValCol.map(fillNA) \n",
    "        TempVals = pointTempValCol.aggregate_array('first').getInfo()\n",
    "        \n",
    "        # Extracting mean dew point values\n",
    "        pointDewValCol = threeBandImage.select('tmean_mean').reduceRegions(collection = sampleCircles,\n",
    "                                                    reducer = ee.Reducer.first(), \n",
    "                                                    crs = proj,\n",
    "                                                    scale = 30 # Same scale as projection and landsat data\n",
    "                                                    )\n",
    "\n",
    "        pointDewValCol = pointDewValCol.set({'year':year})\n",
    "        pointDewValCol = pointDewValCol.map(fillNA) \n",
    "        DewVals = pointTempValCol.aggregate_array('first').getInfo()\n",
    "        \n",
    "        # Creating a list to store all three variable lists for a given year\n",
    "        singleYlists.append([PrecipVals,TempVals,DewVals])\n",
    "        \n",
    "#### ending the timer ####\n",
    "end = datetime.now() \n",
    "duration = end - start\n",
    "# nicely printing the ellapsed time\n",
    "timeList = str(duration).split(':')\n",
    "print('The time elapsed during this execution of this operation was :','\\n',\n",
    "     timeList[0],'Hour(s)','\\n',\n",
    "     timeList[1],'Minute(s)','\\n',\n",
    "      'and',round(float(timeList[2]),ndigits = 0),'Seconds'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the values out of the mess created above\n",
    "yearList = years.getInfo()\n",
    "\n",
    "# Have to integrate the weirdly organized uniqueID's\n",
    "standIDs = pointPrecipValCol.aggregate_array('UniqueID').getInfo()\n",
    "\n",
    "# Creating a seperate dataframe for each climate variable and each climate scenario\n",
    "precipDF = pd.DataFrame(index = standIDs, columns = yearList)\n",
    "TempDF = pd.DataFrame(index = standIDs, columns = yearList)\n",
    "DewDF = pd.DataFrame(index = standIDs, columns = yearList)\n",
    "\n",
    "for year in yearList :\n",
    "    yearIndex = yearList.index(year)\n",
    "    singleYear_allVariables = singleYlists[yearIndex]\n",
    "    precipDF.iloc[:,yearIndex] = singleYear_allVariables[0]\n",
    "    TempDF.iloc[:,yearIndex] = singleYear_allVariables[1]\n",
    "    DewDF.iloc[:,yearIndex] = singleYear_allVariables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting climate values from above\n",
    "precipDF.to_csv(path_or_buf=\"C:/R_workspace/\"+\"PRISM_precipDF_\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')\n",
    "TempDF.to_csv(path_or_buf=\"C:/R_workspace/\"+\"PRISM_tempDF_\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')\n",
    "DewDF.to_csv(path_or_buf=\"C:/R_workspace/\"+\"PRISM_dewDF_\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e649041",
   "metadata": {},
   "source": [
    "### _Setup for Compositing & Extraction Procedure_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter analysis parameters\n",
    "compositeMonthStart = 2 \n",
    "compositeMonthEnd = 3 #inclusive\n",
    "outputIndex = 'B5'\n",
    "\n",
    "# prep for function\n",
    "chart_VI = LS_stack_wVI.filter(ee.Filter.calendarRange(compositeMonthStart,compositeMonthEnd,'month'));\n",
    "proj = potentialSamples2.select('numericL3ecocode').projection()\n",
    "\n",
    "years = ee.List.sequence(1984, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81daf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interting a single constant image into the landsat stack to avoid missing data in 1990\n",
    "zeroImage1 = ee.Image.constant(0.0).clipToBoundsAndScale(loblolly.geometry(),scale = 30).toFloat()\n",
    "zeroImage1 = zeroImage1.rename(['NBR'])\n",
    "\n",
    "zeroImage2 = ee.Image.constant(0.0).clipToBoundsAndScale(loblolly.geometry(),scale = 30).toFloat()\n",
    "zeroImage2 = zeroImage2.rename(['B5'])\n",
    "\n",
    "zeroImage3 = ee.Image.constant(0.0).clipToBoundsAndScale(loblolly.geometry(),scale = 30).toFloat()\n",
    "zeroImage3 = zeroImage3.rename(['EVI2'])\n",
    "\n",
    "zeroImage = zeroImage1.addBands(zeroImage2)\n",
    "zeroImage = zeroImage.addBands(zeroImage3)\n",
    "zeroImage = zeroImage.set('system:time_start', ee.Date.fromYMD(1990,compositeMonthStart,1).millis())\n",
    "\n",
    "chart_VI = chart_VI.merge(zeroImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da77996",
   "metadata": {},
   "source": [
    "### Vegetation Index Extraction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction function that creates annual composites, writes values to a feature collection\n",
    "def annualComposite (year):\n",
    "    filteredColl = chart_VI.filter(ee.Filter.calendarRange(year, year, 'year'))\n",
    "    singleImage = filteredColl.select([str(outputIndex)]).reduce(ee.Reducer.median()) ## CHANGE COMPOSITE STAT HERE ###\n",
    "    outputImage = singleImage.set('system:time_start', ee.Date.fromYMD(year,compositeMonthStart, 1).millis())\n",
    "    outputCollection = outputImage.reduceRegions(collection = sampleCircles,\n",
    "                                                 reducer = ee.Reducer.mean(),\n",
    "                                                 scale = 30\n",
    "                                                )\n",
    "    return outputCollection\n",
    "\n",
    "export_data = ee.FeatureCollection(years.map(annualComposite)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17222790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a batch export process to execute the processes above\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = export_data,\n",
    "                                            description = (outputIndex+\"_values\"+today),\n",
    "                                            folder = 'EarthEngine_Exports',\n",
    "                                            fileFormat = 'CSV',\n",
    "                                            selectors = ['UniqueID','mean']\n",
    "                                            )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf889a",
   "metadata": {},
   "source": [
    "### Phenology Time Series Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "growSZNtemp_col = growSZN_col.select('AVGgrowSZNtemp')\n",
    "growSZNvpd_col = growSZN_col.select('AVGgrowSZNvpd')\n",
    "growSZNprecip_col = growSZN_col.select('TotalgrowSZNprecip')\n",
    "\n",
    "[GDD_col,freeze_col,growSZN_col,growSZNtemp_col,growSZNvpd_col,growSZNprecip_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87051279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction function that selects phenology metrics and exports them to a feature collection\n",
    "def annualExtraction (inImage):\n",
    "    outputImage = inImage.select('seasonLength','midSeasonLength','Peak_1','EVI_Area_1')\n",
    "    outputCollection = outputImage.reduceRegions(collection = sampleCircles,\n",
    "                                                 reducer = ee.Reducer.first(),\n",
    "                                                 scale = 30\n",
    "                                                )\n",
    "    return outputCollection\n",
    "\n",
    "export_data = ee.FeatureCollection(phenology_col.map(annualExtraction)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a batch export process to execute the processes above\n",
    "exportTask = ee.batch.Export.table.toDrive(collection = export_data,\n",
    "                                            description = ('PhenologyMetrics_values'+today),\n",
    "                                            folder = 'EarthEngine_Exports',\n",
    "                                            fileFormat = 'CSV',\n",
    "                                            selectors = ['UniqueID','seasonLength','midSeasonLength','Peak_1','EVI_Area_1']\n",
    "                                            )\n",
    "exportTask.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2abdc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc0584",
   "metadata": {},
   "source": [
    "### Reformatting, Plotting, and Writing Extracted VI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputIndex = 'B5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data exported in the above cell\n",
    "importVI = pd.read_csv('C:/R_workspace/'+outputIndex+'_values_2022_06_29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66a10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reformatting above values into dataframe (one row for each stand, 38 columns for each year)\n",
    "\n",
    "standIDs = np.sort(importVI.iloc[:,0].unique())\n",
    "imageYears = years.getInfo()\n",
    "\n",
    "# Creating the dataframe\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "VItsDF = pd.DataFrame(index = standIDs, columns = imageYears)\n",
    "\n",
    "for stand in standIDs:\n",
    "    singleStandDF = importVI.loc[importVI['UniqueID'] == stand]\n",
    "    VItsDF.iloc[stand,:] = singleStandDF['mean']\n",
    "    \n",
    "VItsDF[1990] = [np.nan]*len(standIDs)\n",
    "\n",
    "# for some reason all the columns dtype is 'object' converting to float above wasn't working so I'll just have to convert the columns\n",
    "for col in VItsDF:\n",
    "    VItsDF[col] = pd.to_numeric(VItsDF[col], errors='coerce')\n",
    "VItsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "if outputIndex == 'B5' :\n",
    "    scaler = MinMaxScaler()\n",
    "    test_df = VItsDF.drop(VItsDF.iloc[:, [6]],axis = 1)\n",
    "\n",
    "    scaler.fit(test_df)\n",
    "    test_df = pd.DataFrame(scaler.transform(test_df))\n",
    "\n",
    "    test_df.insert(6,'1990',([np.nan]*len(standIDs)))\n",
    "    test_df.columns = imageYears\n",
    "    VItsDF = (test_df*-1) +1\n",
    "    \n",
    "VItsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeee48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exporting the dataframe before interpolating missing values\n",
    "VItsDF.to_csv(path_or_buf=\"C:/R_workspace/\"+outputIndex+\"_timeSeriesDF2000\"+today+\"_wNA.csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df0acc",
   "metadata": {},
   "source": [
    "### Creating time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d15a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy as sp\n",
    "import scipy.signal as scisig\n",
    "\n",
    "## interpolation of null values\n",
    "plotDF = VItsDF.interpolate(axis = 'columns',method = 'akima')\n",
    "\n",
    "# setting up for time-series plots\n",
    "fig, axs = plt.subplots(7, 3, sharex=False, sharey=True, figsize = (16,25))\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    ax.plot(plotDF.iloc[i,].transpose(),label = \"Interpolated\")\n",
    "    ax.plot(VItsDF.iloc[i,].transpose(),label = \"Original\")\n",
    "    ax.scatter(imageYears,VItsDF.iloc[i,], color = 'orange',s = 20)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_title(\"Stand\"+' '+str(standIDs[i])+' '+\"Time-Series\")\n",
    "    \n",
    "fig.subplots_adjust(left=0.1, bottom=0.1, right=None, top=None, wspace=0.3, hspace=0.5)\n",
    "fig.text(0.5, 0.04, 'Year', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, (outputIndex+' '+'value'), ha='center', va='center', rotation='vertical')\n",
    "\n",
    "fig.savefig(\"C:/R_workspace/timeSeries_interpolation.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b3f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotDF\n",
    "\n",
    "plotDF.to_csv(path_or_buf=\"C:/R_workspace/\"+outputIndex+\"_timeSeriesDF2000\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d157a53",
   "metadata": {},
   "source": [
    "### Reformatting and Writing Phenology Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data exported in the above cell\n",
    "importMetrics = pd.read_csv(\"C:\\R_workspace\\PhenologyMetrics_values_2022_07_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea784d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformatting above values into dataframe (one row for each stand, 38 columns for each year)\n",
    "\n",
    "standIDs = np.sort(importMetrics.iloc[:,0].unique())\n",
    "numYears = 19\n",
    "imageYears = range(2001,2001+numYears)\n",
    "                   \n",
    "# Creating the dataframe\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "seasonLengthTsDF = pd.DataFrame(index = standIDs, columns = imageYears)\n",
    "midSeasonLengthTsDF = pd.DataFrame(index = standIDs, columns = imageYears)\n",
    "PeakDayTsDF = pd.DataFrame(index = standIDs, columns = imageYears)\n",
    "EVI_AreaTsDF = pd.DataFrame(index = standIDs, columns = imageYears)\n",
    "\n",
    "\n",
    "for stand in standIDs:\n",
    "    singleStandDF = importMetrics.loc[importMetrics['UniqueID'] == stand]\n",
    "    seasonLengthTsDF.iloc[stand,:] = singleStandDF['seasonLength']\n",
    "    midSeasonLengthTsDF.iloc[stand,:] = singleStandDF['midSeasonLength']\n",
    "    PeakDayTsDF.iloc[stand,:] = singleStandDF['Peak_1']\n",
    "    EVI_AreaTsDF.iloc[stand,:] = singleStandDF['EVI_Area_1']\n",
    "    \n",
    "# Converting the peak day value from days since Jan 1, 1970 to days since Jan 1 of the current year\n",
    "yearDayLenList = [365,365,365,366]*5\n",
    "yearDayLenList = yearDayLenList[0:20] # cutting this down to the 19 years\n",
    "\n",
    "PeakDayTsDF = PeakDayTsDF - 11323 # days between 1/1/1970 & 1/1/2001 (not including 1/1/2001)\n",
    "\n",
    "for year in imageYears[1:20]:\n",
    "    yearIndex = imageYears.index(year)\n",
    "    PeakDayTsDF[year] = PeakDayTsDF[year] - sum(yearDayLenList[0:yearIndex])\n",
    "    \n",
    "# for some reason all the columns dtype is 'object' converting to float above wasn't working so I'll just have to convert the columns\n",
    "# for col in phenoTsDF:\n",
    "#     phenoTsDF[col] = pd.to_numeric(phenoTsDF[col], errors='coerce')\n",
    "#seasonLengthTsDF\n",
    "#midSeasonLengthTsDF\n",
    "PeakDayTsDF\n",
    "#EVI_AreaTsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the phenology metric dataframes above\n",
    "seasonLengthTsDF.to_csv(path_or_buf=\"C:/R_workspace/seasonLength_timeSeriesDF\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')\n",
    "midSeasonLengthTsDF.to_csv(path_or_buf=\"C:/R_workspace/midSeasonLength_timeSeriesDF\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')\n",
    "PeakDayTsDF.to_csv(path_or_buf=\"C:/R_workspace/PeakDay_timeSeriesDF\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')\n",
    "EVI_AreaTsDF.to_csv(path_or_buf=\"C:/R_workspace/EVI2_Area_timeSeriesDF\"+today+\".csv\", sep=',', na_rep='', float_format=None, header=True, index=True, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
